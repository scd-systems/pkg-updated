%% 					ATTENTION
%%
%%         	!!! Just edit the ".nw" File !!!
%%
%%			DO NOT EDIT THE .tex FILE'S
%%
<<version>>=
var (
	MAJOR_VERSION=0
	MINOR_VERSION=2
	PATCH_VERSION=7
)
@

\newpage
\section{The Idea}

Simple package update daemon for automated pkg update.
The pkg-updated tackle the update by using the pkg command.

<<TODO>>=
Legend:
[/]	=	Feature implemented but not tested enough / not stable
[x]	=	Featute implemented and stable

Ideas: 
	- For Reporting: Reports about pkg updates needs to report too, and maybe take care of commands running afterwards
	- For Reporting: Output from updated pkg messages must be interpret to add in report as well 
	- [x] Version 0.2: Alpha version
	- [x] Version 0.3: Scheduler
	- [/] Version 0.3: Readme / Howto use
	- [/] Version 0.3: Parametrized program
	- Version 0.3: finalize pkg rollback for failed updates
	- [/] Version 0.4: Check userid and sudo usage
	- [/] Version 0.4: Reporting / Logging
	- Version 0.4: Reporting client command for generate report's
	- Version 0.5: Refactor all variable names and functions
	- Version 0.5: Proper error handling
	- Version 0.5: Port
	- Version 0.5: rc.d script
	- Version 0.5: Finish book and publish first public beta
	- Version 0.6: Fix bugs and Performance issues
	- Version 0.7: FreeBSD Port and SelfUpdate routine
	- Version 0.8: Bugfix / Cleanup documentation
	- Version 0.9: automate schema upgrade if new schema available
	- Version 0.9: Bugfix / Cleanup documentation
	- Version 1.0: Stable Release
	- Version 1.0: Jail support
	- Version 2.0: Update Server which collects all reports and coordinate updates
	- Version 2.0: Desktop: Panel tool for display successful updates

Bugs:
	- If db exists but is empty, the synctodb must run at first (disabled currently)
	- SyncPackages() will remove the rollback package entry in DB (cause of delete db everytime it runs)
	- wrong usage of Slices, read again:
	http://blog.golang.org/go-slices-usage-and-internals

@

\newpage
\subsection{Configuration}
The [[pkg-updated.conf]] parameters in detail.

The [[exclude]] define the packages, which will not updated automatically.
Reports of the pkg upgrade progress will be created if parameter is set true (Boolean). 

<<pkg-updated.conf>>=
{
@

On which time the scheduler should run.
Supported formats: HH:MM[a|A| ][m|M| ]
So, 12 and 24 hour time format are supported

<<pkg-updated.conf>>=
	"schedule": "08:30PM",
@

Be in scheduled time or let the upgrade run if current time is behand scheduled time.
If set false, the pkg-updated will upgrade immediate if the current time is behind the scheduled time.
If set true, the upgrade will start only in a time range from 5 minutes from the scheduled timer.

Example:
1.)
schedule = 09:00PM
schedule-in-time = false
current system time: 12:00PM

The pkg-update will run upgrade immediatly after start.

2.)
schedule = 09:00PM
schedule-in-time = true
current system time: 12:00PM

The pkg-update will NOT run upgrade after the program start.
Instead it will start at 09:00PM

<<pkg-updated.conf>>=
	"schedule-in-time": true,
@


Which packages should never be updated ?
It is also possible to lock packages by "pkg lock <pkg-name>" command
<<pkg-updated.conf>>=
	"exclude-packages": [
		"go"
	],
@

Create a pkg-update report ?
<<pkg-updated.conf>>=
	"create-report": true,
@

Enable automated update ?
<<pkg-updated.conf>>=
	"do-freebsd-update": false,
@

Should a configured daemon restarted after pkg update ?
<<pkg-updated.conf>>=
	"restart-daemons": true,
@

Should all pkg commands run with sudo ?
<<pkg-updated.conf>>=
	"use-sudo": false,
@

If the service restart command fail, should the related package downgrade to the last running version ?
<<pkg-updated.conf>>=
	"downgrade-package-on-failed-restart": true,
@

PKG Archive directory for rollback operations 
<<pkg-updated.conf>>=
	"pkg-archive-enable": true,
	"pkg-archive-directory": "./archive",
@

The pkg-updated Database file which contains the package informations.
The pkg-database-file is the OS database which contains the installed pkg's.
The database-file is for pkg-updated it self for store package informations.
The report-database-file is for logging and reporting of pkg-updated.

<<pkg-updated.conf>>=
	"pkg-database-file": "/var/db/pkg/local.sqlite",
	"database-file": "./pkg-updated.sqlite",
	"report-database-file": "./report.sqlite",
@

Should the pkg-updated DB synchronized on every boot
If set to true, the DB will delete on every start of the program.
All rollback package information's are lost, so no automate rollback possible !

<<pkg-updated.conf>>=
	"fresh-db-sync-on-start": false
@


<<pkg-updated.conf>>=
}
@

\subsection{Read the configuration}

We must read and interpret the configuration file.

The default config file name must be defined as well as the struct. 

<<pkg-updated.go: variables>>=
const config_file = "./pkg-updated.conf"; 
@

Made with: https://mholt.github.io/json-to-go/

<<pkg-updated.go: variables>>=
var config struct {
	RecurTime string `json:"schedule"`
	StrictRecurTime bool `json:"schedule-in-time"`
	ExcludePackages []string `json:"exclude-packages"`
    CreateReport bool `json:"create-report"`
	ClearSyncDatabaseEnabled bool `json:"fresh-db-sync-on-start"`
    DoFreebsdUpdate	bool `json:"do-freebsd-update"`
    RestartDaemons bool	`json:"restart-daemons"`
    DowngradePackageOnFailedRestart	bool `json:"downgrade-package-on-failed-restart"`
	UseSudo bool `json:"use-sudo"`
	ArchiveEnable bool `json:"pkg-archive-enable"`
    ArchiveFile string `json:"pkg-archive-directory"`
    PkgDatabaseFile string `json:"pkg-database-file"`
    DatabaseFile string `json:"database-file"`
    ReportDatabaseFile string `json:"report-database-file"`
    Param_DebugMode *bool;
    FileExistsNoLog bool;
};
@

To use json, we need the json package

<<pkg-updated.go: modules>>=
"encoding/json"
@

<<pkg-updated.go: readconfig>>=
func ReadConfig() {
	configfile, err := os.Open(config_file);
	if err != nil {
		logging(LOG_FATAL, "readconfig", fmt.Sprintf("Cannot open config file: %s", config_file));
	}
	defer configfile.Close();

	jsonParser := json.NewDecoder(configfile)
	
	if err = jsonParser.Decode(&config); err != nil {
		logging(LOG_FATAL, "readconfig", fmt.Sprint("Failed to read/parse config: %s", err));
	}
	logging(LOG_DEBUG, "readconfig-parsed", fmt.Sprint(config));
}
@
<<TODO>>=
// 20160309: Need to set default config parameters if no parameters set in configfile
@


\newpage
\section{Update vs. Upgrade}

What is an update and what is an upgrade ?
This question is not easy to answer.
In general, if the Major version of a Software change, then we talk about an Upgrade.
So an update means if from Version x to Version y the minor number have been changed.

\newpage
\section{The Work flow for automated package update}

The general progress for the pkg-updated have to be:

1.) Get current installed packages from existing Database.
If the existing Database does not exists, test if /usr/local/ and subdirectories or files exists.
If a /usr/local directory tree exist's without any pkg information databases the program have to stop for secure.
When the database exists the program have to analyze all installed packages by files and directories.

2.) Create a backup of all installed packages and store it under /var/backup or similar directory
In case of upgrade failure, we are able to rollback the system to a stable state back
We can also check under /var/cache/pkg for installed versions.

3.) If the backup successfully done, we can check for updates.
This can be done by pkg version command.

4.) Scan for enabled services and collect the related package.
This i needed for automatic service restart after pkg upgrade is done and a service was affected took.
Like apache package update needs to restart the httpd after upgrade.
Before the upgrade starts, some steps have to be done before:

- Read enabled services from rc.conf and check service scripts for the target command.
- If the target daemon command available, verify the path/bin with the pkg db information and detect the pkg name.
- Get all running daemons and used config files
	
5) Now update all non-critical packages if possible and not locked

6) Restart a service after update (example Apache)

If the service restart command failing or the daemon does not come up after a while, the update process are failed at all.
The daemon must re-install the old package and mark the update as broken. 

7) Rollback packages if the service restart was not succesful. In this case, we expect a wrong package and hope the rollback will 
bring the system back in stable mode.

\newpage
\section{Get current installed packages from existing Database}

The pkg program use sqlite as database for store all package related information's.
This database will be used to fetch all related information's as source for the update daemon.


Follow go modules are used:
<<pkg-updated.go: modules>>=
"fmt"
"os"
"strconv"
@

\newpage
\subsection{The sqlite connection}

We need a sqlite driver for go to connect and read the database schema.
There are a lot of sqlite3 drivers available for golang, but not all supports the golang database/sql interface.
I will use "https://github.com/mattn/go-sqlite3", because its support the golang sql interface.

<<pkg-updated.go: modules>>=
"database/sql"
_ "github.com/mattn/go-sqlite3"
@


We need a function to verify if the pkg-updated database already exists or not.
Also we need a function to initialize an empty database.

<<pkg-updated.go: sqlite-connect>>=
func FileExists(filename string) int {
	_, err := os.Stat(filename)
	if os.IsNotExist(err) {
		if (config.FileExistsNoLog == false) {
			logging(LOG_ERROR, "fileexists-stat", fmt.Sprint(err))
		} else {
			config.FileExistsNoLog = false;
		}
		return -1;
	}
	return 0;
}

func OpenDB(filename string) *sql.DB {
	db, err := sql.Open("sqlite3", filename);
	if err != nil {
		logging(LOG_ERROR, "opendb", fmt.Sprint(err))
		log.Fatal(err);
	}
	return db;
}

func CreateDatabase(db *sql.DB, id int) int {
	
	<<pkg-updated.go: sqlite-schema>>

	_, err := db.Exec(DBSchema[id]);
	if err != nil {
		logging(LOG_ERROR, "createdb", fmt.Sprintf("Schema: %s | error: %s", DBSchema[id], err))
		return -1
	}	
	return 0;
}
@

In addition some other functions are needed, like add package with name and status, delete a package from database.
The function [[GetPackageInfo]] is used to report the current information's of a package.

<<TODO>>=
// TODO: function + Return code 	-> string, retcode/error
// TODO: AddPackageDB: detect duplicate entries and avoid !!!
// TODO: Use function handling with: func name(arg1 int, rest...);
// 20160212: GetPackageInfo(): Need to find better code for dynamic requests (table, field, ...)
@

We need a help function for count(*) because

<<pkg-updated.go: sqlite-connect>>=
func CountRows(db *sql.DB, table string, column string, search string) int {
	var result int;	

	err := db.QueryRow("SELECT count(*) FROM "+ table +" WHERE "+ column +" = '"+ search +"';").Scan(&result)
	if err != nil {
		logging(LOG_ERROR, "countrows", fmt.Sprint(err));
		return -1;
	}
	logging(LOG_DEBUG, "countrows", fmt.Sprintf("sql query: SELECT count(*) FROM %s WHERE %s = %s | count(*): %d", table, column, search, result));
	return result
}
@

First check if row exists, if not break an return "not exists";

<<pkg-updated.go: sqlite-connect>>=
func GetPackageInfo(db *sql.DB, field string, pkgname string, opts... string) (string, error) {
	var (
		result string;
		res *string;
		err error;
		stmt *sql.Stmt;
		count int;
	)

	if (len(opts) > 0) {
		if (len(opts) < 2) {
			count = CountRows(db, opts[0], "name", pkgname);
		} else {
			count = CountRows(db, opts[0], opts[1], pkgname);
		}
	} else {
		count = CountRows(db, "packages", "name", pkgname);
	}
			
	if (count < 0) {
		result = "ENOSQLOUT";
		return result, nil;
	}
	
	if (count == 0) {
		result = "ENOEXIST";
		return result, nil;
	}

	if (len(opts) > 0) {
		if (len(opts) < 2) {
			stmt, err = db.Prepare("SELECT "+field+" FROM "+ opts[0] +" WHERE name = ?");
		} else {
			stmt, err = db.Prepare("SELECT "+field+" FROM "+ opts[0] +" WHERE "+ opts[1] +" = ?");
		}
	} else {
		stmt, err = db.Prepare("SELECT "+field+" FROM packages WHERE name = ?");
	}
	if err != nil {
		log.Fatal(err);
		return result,fmt.Errorf("%s", err);
	}

	err = stmt.QueryRow(pkgname).Scan(&res);

	if (res != nil) {
		result = *res;
	} else {
		result = "NULL";
		return result, nil;
	}
	if err != nil {
		log.Fatal(err);
		return result,fmt.Errorf("%s", err);
	}

	return result, nil;
}
@

Add package and update package function !

<<pkg-updated.go: sqlite-connect>>=
func AddPackage(db *sql.DB, name string, origin string, version string, status string) int {	
	tx, err := db.Begin();
	if err != nil {
		log.Fatal(err);
	}
	stmt, err := tx.Prepare("insert into packages(name, origin, version, status) values(?, ?, ?, ?)");
	if err != nil {
		log.Fatal(err);
		return -1;
	}
	defer stmt.Close()
	_, err = stmt.Exec(name, origin, version, status);

	if err != nil {
		log.Fatal(err);
		return -1;
	}
	tx.Commit();
		
	return 0;
}
@

The [[UpdatePackage]] function is used to ....

<<pkg-updated.go: sqlite-connect>>=
func UpdatePackage(db *sql.DB, set_field string, set_value string, where_field string, where_value string, opts... string) int {
	var	query string;
	
	tx, err := db.Begin();
	if err != nil {
		logging(LOG_ERROR, "updatepackage", fmt.Sprint(err));
	}

	if len(opts) > 0 {
		query = "UPDATE "+ opts[0] + " SET "+set_field+" = ? WHERE "+where_field+" = ?";	
	} else {
		query = "UPDATE packages SET "+set_field+" = ? WHERE "+where_field+" = ?";
	}

	logging(LOG_DEBUG, "updatepackage", fmt.Sprintf("sql query: %s | Params: %s;%s", query, set_value, where_value));
	
	stmt, err := tx.Prepare(query);
	if err != nil {
		logging(LOG_ERROR, "updatepackage", fmt.Sprint(err));
		return -1;
	}
	defer stmt.Close()
	_, err = stmt.Exec(set_value, where_value);
	if err != nil {
		logging(LOG_ERROR, "updatepackage", fmt.Sprint(err));
		return -1;
	}
	tx.Commit();
	return 0;
}
@

Function to return all available package names as splice

<<pkg-updated.go: sqlite-connect>>=
func GetAllPackages(db *sql.DB) ([]string, error){
	var (
		result []string;
		name string;
	)
	
	rows, err := db.Query("SELECT name FROM packages");
	if err != nil {
		logging(LOG_ERROR, "getallpackages", fmt.Sprint(err));
	}
	defer rows.Close();
	
	result = make([]string, 1)
	tmp_result := make([]string, 1);
	i := 0
	for rows.Next() {
		rows.Scan(&name)
		tmp_result[i] = name;
		copy(result, tmp_result);
		tmp_result = make([]string, len(result)+1);
		copy(tmp_result, result);
		result = make([]string, len(result)+1);
		i++;

	}
	result = make([]string, len(tmp_result)-1);
	copy(result, tmp_result);
	return result, err;
}
@


Add Service function.
Need enable as parameter as soon as enabled service detection is ready and working:

<<pkg-updated.go: sqlite-connect>>=
func AddService(db *sql.DB, name string, svccmd string, enabled int) int {	
	tx, err := db.Begin();
	if err != nil {
		logging(LOG_ERROR, "addservice", fmt.Sprint(err));
	}
	stmt, err := tx.Prepare("insert into services (name, svccmd, enabled) values (?, ?, ?)");
	if err != nil {
		logging(LOG_ERROR, "addservice", fmt.Sprint(err));
		return -1;
	}
	defer stmt.Close()
	_, err = stmt.Exec(name, svccmd, enabled);
	
	if err != nil {
		logging(LOG_ERROR, "addservice", fmt.Sprint(err));	
		return -1;
	}
	tx.Commit();
		
	return 0;
}
@

\subsection{Schema layout description}

Which fields are required for the pkg-update daemon it self.

Packages Schema:

- Installed package names and versions
- Current status of a packages, (up-to-date, update-available)
- Index over the name field
- Origin
- Rollback-PkgFile
- Lockstatus
- Service Command svccmd

Services Schema:
- id
- name
- svccmd
- enabled

For jailed version need additional in package and service schema:
- host

<<pkg-updated.go: sqlite-schema>>=
	var DBSchema []string;
	DBSchema = make([]string, 2)
	DBSchema[0] = "CREATE TABLE packages (id INTEGER NOT NULL PRIMARY KEY, name TEXT NOT NULL UNIQUE, origin TEXT, version TEXT NOT NULL, status TEXT NOT NULL, archivepath TEXT, lockstatus TEXT); CREATE INDEX package_name ON packages(name COLLATE NOCASE);CREATE TABLE services (id INTEGER NOT NULL PRIMARY KEY, name TEXT NOT NULL, svccmd TEXT, enabled TEXT);";
@

The Reporting Database needs follow schema
- timestamp
- eventtype
- facility
- message

<<pkg-updated.go: sqlite-schema>>=
	DBSchema[1] = "CREATE TABLE report (id INTEGER NOT NULL PRIMARY KEY, timestamp INTEGER, eventtype TEXT, facility TEXT, message TEXT NOT NULL); CREATE INDEX report_type ON report (eventtype COLLATE NOCASE);";
@

\newpage
\section{Detailed workflow}

First parse all parameters and then read config and handle errors.
Afterwards check and open the database.

<<pkg-updated.go: main>>=
func main(){

<<pkg-updated.go: parameter>>

@

At first, we read the configuration file and initialize the Database connections.
If databases not exists, we create them.
The report database will just open once for creating.
After creating the report db, the file handle will close for access the report db again.

<<pkg-updated.go: main>>=
	ReadConfig();
	Check();

	logging(LOG_EVENT, "main", "Started pkg-updated"); 

// Need to find a better code for open file only if exists and not before test file.

	var ret int;			
	db := OpenDB(config.DatabaseFile);
	defer db.Close();
	ret = FileExists(config.DatabaseFile);	
	logging(LOG_INFO, "main", fmt.Sprintf("Check packages Database %s: %d", config.DatabaseFile, ret));	

	if ret != 0 {
		ret = CreateDatabase(db, 0);
		if ret != 0 {
			logging(LOG_ERROR, "main", "Create packages database: failed");	
			os.Exit(2);
		} else {
			logging(LOG_INFO, "main", "Create packages database: done");	
		}
	}
	
	ret = FileExists(config.ReportDatabaseFile);	
	logging(LOG_INFO, "main", fmt.Sprintf("Check report Database %s: %d", config.ReportDatabaseFile, ret));	

	if ret != 0 {
		reportdb := OpenDB(config.ReportDatabaseFile);
		ret = CreateDatabase(reportdb, 1);
		if ret != 0 {
			logging(LOG_ERROR, "main", "Create report database: failed");
			reportdb.Close();
			os.Exit(2);
		} else {
			logging(LOG_INFO, "main", "Create report database: done");	
		}
		reportdb.Close();
	}

@

After database initialize, we switch over to the Scheduler.	And sleep for ever in the main.
Maybe need to implement some self-healing checks every five minutes or other tasks.

<<pkg-updated.go: main>>=
	go Scheduler(db);
	for {
		RunCmd("sleep", "300");	
	}
@
<<TODO>>=
// 20160305: Need to find a better way instead of sleep !
@


In every iteration round from daemon, we must synchronize the local package information's to the pkg-updated database.
This is necessary, because pkg-updated will never touch the pkg databases it self, it will use his own.
The synchronization is quiet simple, copy over all package names, version from local pkg-database and fill into the pkg-updated DB.
			

<<pkg-updated.go: syncdb>>=
func SyncPkgDatabases(db *sql.DB) error {
	dbpkg := OpenDB(config.PkgDatabaseFile);
	defer dbpkg.Close();

	var (
		lockstatus string;
		pkglist []string;
		err error;
		request string;
	)
	
	pkglist,err = GetAllPackages(db);

	if (len(pkglist) > 1) {
		for _,name := range pkglist {
			if lockstatus, err = GetPackageInfo(db, "lockstatus", name); err != nil {	
				logging(LOG_ERROR, "syncpkgdatabase", fmt.Sprintf("Current Lockstatus Error: %s", err));
			}
			if (lockstatus == "1") {
				logging(LOG_INFO, "syncpkgdatabase", fmt.Sprintf("Unlock excluded packages before sync: %s", name));
				LockPackage(db, 0, name);
			}
		}
	}
		
	if (config.ClearSyncDatabaseEnabled == true){
		logging(LOG_INFO, "syncpkgdatabase", "Fresh pkg databases syncronize");
		_, err = db.Exec("DELETE FROM packages");
		if err != nil {
			logging(LOG_ERROR, "syncpkgdatabase", fmt.Sprintf("Clear pkg-updated database: failed | Error: %s", err));
			return err;
		}	
		logging(LOG_INFO, "syncpkgdatabase", "Clear pkg-updated database: done");
	} 

		
	rows, err := dbpkg.Query("SELECT name, version, origin, locked FROM packages");
	if err != nil {
		logging(LOG_ERROR, "syncpkgdatabase", fmt.Sprintf("Sync pkg database: failed | Error: %s", err));
	}
	defer rows.Close();

	var (
		name string;
		version string;
		origin string;
		locked int;
	)
	
@
<<TODO>>=
// 20160124: SyncPackageDB() -> Use message-queue and go routine for faster copy process
@

Sync all packages from system to pkg-updated db.
Also update the lock.

And, only update the information's if changes are detected otherwise leaf it as it is.
If [[fresh db sync on start]] is enabled, the information's will add, because the DB is clear from begin the function

<<pkg-updated.go: syncdb>>=
	for rows.Next() {
		rows.Scan(&name,&version,&origin,&locked);
		request, err = GetPackageInfo(db, "name", name);
		if (request != "ENOEXIST") {
			request, err = GetPackageInfo(db, "version", name);
			if (request != version) {
				UpdatePackage(db, "version", version, "name", name);
			}
			request, err = GetPackageInfo(db, "origin", name);
			if (request != origin) {
				UpdatePackage(db, "origin", origin, "name", name);
			}			
			request, err = GetPackageInfo(db, "status", name);
			if (request == "update-available") {
				UpdatePackage(db, "status", "up-to-date", "name", name);
			}
		} else {
			AddPackage(db, name, origin, version, "up-to-date");
		}

		if (locked != 0) {
			UpdatePackage(db, "lockstatus", "2", "name", name);
		}
	}
	logging(LOG_INFO, "syncpkgdatabase", "Sync pkg database: done");
	return nil;
}
@

After synchronization, we are ready for check available updates.
This job can do by pkg program it self, we just need the output.
The commands to run are: [[pkg version]]

<<pkg-updated.go: modules>>=
"os/exec"
"bytes"
@

We extract all available updates from pkg version command and update this information inside the DB.
For the extraction, we parse the whole output from the exec command.


<<pkg-updated.go: check-updates>>=
func CheckUpdates(db *sql.DB){
	var (
		cmdOut string
		err    error
		pkgname bytes.Buffer
	)

	cmdOut, err = RunCmd("version");

	if err != nil {
		logging(LOG_ERROR, "checkupdates", fmt.Sprintf("There was an error running pkg command: %s", err));
	}

	// 60 == '<'
	// 10 == SPACE
	// 32 == C.R.
	for n:=0;n<len(cmdOut);n++ {
		if (cmdOut[n] == 60) {
			UpdatePackage(db, "status", "update-available", "origin", pkgname.String());
			pkgname.Reset();
			continue;
		}
		if (cmdOut[n] == 10) {
			pkgname.Reset();
			continue;
		}
		if (cmdOut[n] != 32) {
			pkgname.WriteString(string(cmdOut[n]));
		}
	}
}
@

\newpage
\subsection{The update process}

1. Save installed packages

All packages where an update is available, the pkg-updated will create a rollback package in case the upgrade will fail and the old package needs to installed again. The pkg system does not support downgrade options right now.

<<pkg-updated.go: update>>=
func GetUpdateList(db *sql.DB) ([]string, error){
	var list []string
	var name string
	list = make([]string, 0)
	var nlist []string;

	rows, err := db.Query("SELECT name FROM packages WHERE status = $1", "update-available")
	if err != nil {
		logging(LOG_ERROR, "getupdatelist", fmt.Sprint(err));
		return list, fmt.Errorf("%s", err)
	}
	defer rows.Close()
	
	for rows.Next() {
		nlist = make([]string, len(list)+1);
		copy(nlist,list);
		list = nlist;
		err = rows.Scan(&name)
		if err != nil {
			logging(LOG_ERROR, "getupdatelist", fmt.Sprint(err));
			return list, fmt.Errorf("%s", err)
		}
		list[len(list)-1] = name
	}
	return list, nil
}
@

Iterate through the package list which marked as update-available.
Create the archive packages for backup and save the archive path and file back to database.
Before start with archive packages, we check if the package already exists

<<pkg-updated.go: update>>=
func SavePackages(db *sql.DB){
	var (
		version string;
		origin string;
		path string;
		index int;
	)

	updatelist, err := GetUpdateList(db);
	if err != nil {
		logging(LOG_ERROR, "savepackages", fmt.Sprintf("GetUpdateList(): %v", err));
	}

@
<<TODO>>=
// TODO: Put name and version in a 2d slice/array as return from GetUpdateList() !
@

<<pkg-updated.go: update>>=
	for _, pkg := range updatelist {
		version, err = GetPackageInfo(db, "version", pkg);
		path = config.ArchiveFile + "/" + pkg + "-" + version + ".txz";
		if _, err := os.Stat(path); err != nil {
			RunCmd("create", config.ArchiveFile, pkg)
			index++;
		}
	}

	for _, pkg := range updatelist {
		version, err = GetPackageInfo(db, "version", pkg);
		path = config.ArchiveFile + "/" + pkg + "-" + version + ".txz";
		if _, err := os.Stat(path); err == nil {
			origin, err = GetPackageInfo(db, "origin", pkg);
@
<<TODO>>=
// TODO: Need to use nil error return correctly !
@
<<pkg-updated.go: update>>=
//			if err != nil {
				UpdatePackage(db, "archivepath", path, "origin", origin)
//				UpdatePackage(db, origin, "archive", path)
//			}		
		} else {
			logging(LOG_ERROR, "savepackages", fmt.Sprintf("Could not found rollback package file: %s", path));
		}
	}	
}
@


2. Start Update and analyze output
The upgrade process it self is quiet simple a runcmd step only

<<pkg-updated.go: update>>=
func Upgrade(){
	var (
		cmdOut string;
		err error;
	)
	cmdOut, err = RunCmd("upgrade");
	logging(LOG_STDOUT, "upgrade", fmt.Sprintf("Output Upgrade(): %s", cmdOut));
	if err != nil {
		logging(LOG_ERROR, "upgrade", fmt.Sprintf("Error: ", string(cmdOut), err));
	}
}
@

After upgrade let sync the database again, questions are:

Do we need to sync from fresh ? (check needed)
Otherwise the DB will corrupt after a while.
Problems with sync and clear DB:
- The rollback paths will gone

Downgrade failed updates, needed for late usage

<<pkg-updated.go: rollback>>=
func RollbackPackage(db *sql.DB, name string){
	var (
		path string;
		cmdOut string;
		err error;		
	)
	
	if path, err = GetPackageInfo(db, "archivepath", name); err != nil {
		logging(LOG_ERROR, "rollbackpackage", fmt.Sprintf("Error to get archivepath: %v", err));
	}
	
	if (path == "NULL") {
		logging(LOG_ERROR, "rollbackpackage", fmt.Sprintf("Rollback Error: No rollback pkg available for package %s", name));
		return;
	}
	logging(LOG_ERROR, "rollbackpackage", fmt.Sprintf("Rollback package: %s , pkg: %s",name, path))
		
	if cmdOut, err = RunCmd("install", path); err != nil {	
		logging(LOG_ERROR, "rollbackpackage", fmt.Sprintf("Install error: %s", err));
	}

	/* Set status for success rollback
	 else {
		UpdatePackage(db, "status", "update-available", "name", name);
	}
	*/
	logging(LOG_DEBUG, "rollbackpackage", fmt.Sprintf("Output: %s", string(cmdOut)))
	return;
}
@

<<TODO>>=
// 20160201: Implement error handling
@


\subsubsection{Exclude packages from update process}

Excluded packages must be protect for dependencies from other packages during the update process.
The best option to do that is, the we lock the package in the pkg database directly.

[[pkg lock]] is the Command for doing this

But we must unlock the package after the update/upgrade is done.

And, we must be sure, that already locked packages are not unlocked.
So we must save the current lock before begin to lock excluded packages.
And we must unlock the packages again, except of already locked packages after upgrade is done

%Under some circumstances, you do not want to update packages automatically.
%For this case, the pkg system have a lock feature, which we can use to lock packages before we update the packages.
%Afterwards the package will unlocked.
%One problem must be tackled anyhow. 
%If a packaged already locked before pkg-updated is running, the program must keep the lock status after update is done.
%So we check all current locked packages and save this information into the pkg-update db.

First of all, we need a function to set and get the lockstatus.
I decide to use one function to use, because locking is either set or you just want to know the status.

There are three states [[empty]], [[locked]] and [[systemlock]]. 
If a package is not locked, the state is empty. If a package is in the exclude list from the pkg-updated.conf, the status is set to locked.
The third status is systemlocked and means packages which are already locked on the local repo.
Packages which are marked as locked on the systemlevel will not unlocked after upgrade process, all other packages will unlocked.

	Use case:
		- pkg-updated set lock status from excluded list and breaks
		on the next run, the syncdb will mark the package as systemlocked instead normal locked.
		-> This needs to be handled in syncdb()

Steps need in LockPackage:
- First check the current status
- If already locked and the target state
:
:

<<pkg-updated.go: lock>>=
func LockPackage(db *sql.DB, lock int, name string) string {
	var (
		lockstatus string;
		err error;
	)

	if lockstatus, err = GetPackageInfo(db, "lockstatus", name); err != nil {	
		logging(LOG_ERROR, "lockpackage", fmt.Sprintf("Error: %v", err));
	}
	if (lockstatus == "ENOEXIST") {
		lockstatus = "Package not exists"
		return lockstatus;
	}	
	
	if (lockstatus == "2") {
		lockstatus = "systemlocked";
		return lockstatus;
	}

@
<<TODO>>=
// 20160209: Improve string/int usage in LockPackage
@

<<pkg-updated.go: lock>>=
	switch lock {
		case 0:
			if _, err = RunCmd("unlock", name); err != nil {	
				logging(LOG_ERROR, "lockpackage", fmt.Sprintf("Unlock pkg error: %v", err));
			}				

		case 1:
			if _, err = RunCmd("lock", name); err != nil {	
				logging(LOG_ERROR, "lockpackage", fmt.Sprintf("Lock pkg error: %v", err));
			}	
		default:
			lockstatus = "Not supported lock mode";
			return lockstatus;
	}
	
	setlock := strconv.Itoa(lock);
	
	UpdatePackage(db, "lockstatus", setlock, "name", name);

	lockstatus,err = GetPackageInfo(db, "lockstatus", name);

	switch lockstatus {
		case "NULL":
			lockstatus = "Not locked";
		case "ENOEXIST":
			lockstatus = "Packages does not exists or unlocked";
		case "1":
			lockstatus = "Locked";		
		case "2":
			lockstatus = "Systemlocked";
		default:
			lockstatus = "Unknown lock status";		
	}
	return lockstatus;
}
@

Now lets iterate the exclude list and mark the package as locked in the local pkg repo.

<<pkg-updated.go: lock>>=
func LockExclude(db *sql.DB, lock int) {
	var mode string;
	switch lock {
		case 0:
			mode = "Unlock";
		case 1:
			mode = "Lock";
		default:
			logging(LOG_ERROR, "lockexclude", fmt.Sprintf("The lock id is not supported"));
			return;			
	}
	for _,name := range config.ExcludePackages {
		logging(LOG_INFO, "lockexclude", fmt.Sprintf("%s exclude package %s: %s", mode, name, LockPackage(db, lock, name)));
	}
}
@
<<pkg-updated.go: lockexclude>>=
	LockExclude(db,1);
@

<<pkg-updated.go: unlockexclude>>=
//	LockExclude(db,0);
@


<<pkg-updated.go: main>>=
}
@

\subsection{The daemon}

What needs to be run inside the loop ?
Really needed ?
FreeBSD have the daemon command.

\subsection{The scheduled updated}

If configured, the daemon are allowed to start the update if the time reached.
How to handle the timing exact ?

The scheduler will first detect the configured time format from the parameter.
Then it parse it agains a value time format from golang.
That is necessary to have all time function's available for using.
Because to detect time jump's like on daylight saving days, the Unix Timestamp diffential from the last minute 
of check and the current timestamp will compare.

This check will detect all time jumps (forward and backward).
Example:
So, if the the schedule time is configured for at 02:00 o'clock in the morning (AM), and the summer daylight saving is exact on this day, the job will then run at 03:00 AM exactly when the time jump was detected.
On the end of October it is nearly the same, but in this case, the job will run twice at 02:30 AM.

We must use RunCmd for sleep, because the time in golang is not time backward aware !!!
So it is just possible to detect time forward jumps, but not backwards.
But we need to detect jumps in both directions to handle daylight saving time correctly.

We need regexp module to detect the daytime format from the [[schedule]] config parameter value

<<pkg-updated.go: modules>>=
"regexp"
"time"
@

<<pkg-updated.go: scheduler>>=
func Scheduler(db *sql.DB){
	var (
		err error;
		recur time.Time;
		AlreadyRun bool;
		Ticker int;
		TimeNow time.Time;
		LastCheck time.Time;
		romandaytime bool;
		sleeptimer int;
		tolerance int;
		Run bool;
		diff int64;
		diff2 int;
		RecurUnixStamp int;
	)

	sleeptimer = 60;
	tolerance = 10;

	romandaytime = false;
	re := regexp.MustCompile("[0-9][0-9][a|A|p|P][m|M]$")
	ret := re.FindString(config.RecurTime);

	if (len(ret) > 0) {
		romandaytime = true;
	}

	if (romandaytime) {
		recur, err = time.Parse(time.Kitchen, config.RecurTime);
	} else {
		var buffer bytes.Buffer
		buffer.WriteString("24 Dec 00 ")
		buffer.WriteString(config.RecurTime)
		buffer.WriteString(" UTC")
		value := buffer.String();
		recur, err = time.Parse(time.RFC822, value);
	}
	if(err != nil) {
		logging(LOG_ERROR, "scheduler", fmt.Sprintf("Cannot parse schedule value: %s", err));
	}

	logging(LOG_DEBUG, "scheduler", fmt.Sprintf("Recurring time: %v:%v", recur.Hour(), recur.Minute()));

	LastCheck = time.Now();
	RecurUnixStamp = (recur.Hour()*3600)+(recur.Minute()*60);	

	for {
		TimeNow = time.Now();
		diff = LastCheck.Unix() - TimeNow.Unix();
		Ticker = (TimeNow.Hour()*3600)+(TimeNow.Minute()*60)+(TimeNow.Second());
        
		LastCheck = TimeNow;
		if ((diff <= (0 - int64(sleeptimer)-int64(tolerance))) || (diff > (int64(sleeptimer)+int64(tolerance)))) {
			logging(LOG_INFO, "scheduler", "Time jump detected");
			logging(LOG_INFO, "scheduler", "Set AlreadyRun to false");
			AlreadyRun = false;
		}		

		// Only run if time has been arrived

		if ( (AlreadyRun == false) && ((TimeNow.Hour() > recur.Hour()) || ( (TimeNow.Hour() == recur.Hour()) && (TimeNow.Minute() >= recur.Minute()) ))) {

			// If strict time is configured, check the 5 minute tolerance

			if (config.StrictRecurTime == true){
				Run = false;
				diff2 = Ticker - RecurUnixStamp;
				if((diff2>0) && (diff2<300)) {
					Run = true;
				}
			} else {
				Run = true;
			}			

			if (Run == true) {
				logging(LOG_EVENT, "scheduler", fmt.Sprintf("Scheduled Time reached, start job"));

				SyncPkgDatabases(db);
				CheckUpdates(db);
				if config.ArchiveEnable {
					SavePackages(db);
				}
				LockExclude(db, 1);
				ScanEnabledServices(db)
	
				Upgrade();
	
				/* Second RUN
					Need to verify how it behaves 
				
				if config.ClearSyncDatabaseEnabled == true {
					config.ClearSyncDatabaseEnabled = false
				}
				SyncPkgDatabases(db)
				*/
				
				AlreadyRun = true;
				Run = false;
			}
		}

		if ((Ticker >= (86400-sleeptimer-tolerance)) && (AlreadyRun == true)){
			logging(LOG_INFO, "scheduler", fmt.Sprintf("New day detect, set AlreadyRunn to false"));
			AlreadyRun = false;
		}

		logging(LOG_DEBUG, "scheduler", fmt.Sprintf("Recur: %v:%v | Now: %v:%v | AlreadyRun: %v", recur.Hour(), recur.Minute(), TimeNow.Hour(), TimeNow.Minute(), AlreadyRun));

        RunCmd("sleep", strconv.Itoa(sleeptimer));
	}
}
@


\newpage
\subsection{Update running services}

What we need to do here.

First we need to determine if a service is related to the installed packages.
This can be done by check files under /usr/local/etc/rc.d directory.

Second, we check which package have this service file provided 

Third, update the database with the related service script

In the last step, the service needs to restart after update(), and only if package was updated
For this, we can check the update-available status from the db.

We need a function to restart a service
We need a function to detect installed and enabled services


- Detect package names form service scripts
	pkg which /usr/local/etc/rc.d/vboxnet

- Detect enabled services:
check rcvar
check enabled
	if enabled -> check daemon is running
		if daemon is running, 

<<pkg-updated.go: modules>>=
"io/ioutil"
@

Search the related packages from the service scripts from in the directory /usr/local/etc/rc.d
One problem could be appear if a pkg have more then one service script, like apache have (apache and htcacheclean).

<<pkg-updated.go: services>>=
func ScanEnabledServices(db *sql.DB){
	if (config.RestartDaemons == true) {
		var (
			pkgorigin string;
			pkgname string;	
			ret int;
			err error;
			enabled int;
			cmdout string;
		)
		enabled = 0;
		
		_, err = db.Exec("DELETE FROM services");
		if err != nil {
			logging(LOG_ERROR, "scanenabledservices", fmt.Sprintf("Truncated service db: failed | Error: %s", err));
			return;
		}	
		logging(LOG_INFO, "scanenabledservices", "Truncated service db: done");
		
		absolute := "/usr/local/etc/rc.d/";				
		files,_ := ioutil.ReadDir(absolute)
		
		for _, f := range files {
			if (f.IsDir() == false) {
				svc := absolute + f.Name();
				pkgorigin, err = RunCmd("which", svc);
				if err == nil {

					pkgname, err = GetPackageInfo(db, "name", chop(pkgorigin), "packages", "origin");
				
					logging(LOG_DEBUG, "scanenabledservices", fmt.Sprintf("Pkgname for origin %s: %s", chop(pkgorigin), pkgname));
					logging(LOG_DEBUG, "scanenabledservices", fmt.Sprintf("Add %s: %s", pkgname, svc));

					ret,cmdout,err = ScanScript(svc, cmdout);
					if (ret != 0) {
						logging(LOG_DEBUG, "scanenabledservices", fmt.Sprintf("Service: %s is enabled", svc));
						enabled = 1;
					} else {
						logging(LOG_DEBUG, "scanenabledservices", fmt.Sprintf("Service: %s is not enabled", svc));
						enabled = 0;				
					}
					AddService(db, pkgname, svc, enabled);
				}
			}
		}		
	}
}
@

Detection of enabled services.
How to detect enabled services ?
We use [[service -e]] command on FreeBSD to detect enabled Services.
The output from the command will parse and if the service is enabled, the function [[ScanScript]] will return 1 for found and 0 for not-found.
To reduce the cmd calls from [[RunCMD]] function, the cmdout will returned and can be handover again in an upper iteration [[ScanEnabledServices]]

<<pkg-updated.go: services>>=
func ScanScript(path string, preout string) (int, string, error) {
	var (
		err error;
	)
	var cmdOut string;
	if (preout != "") {
		cmdOut = preout;
	} else {
		cmdOut,err = RunCmd("service", "");
	}

	if err != nil {
		return -1, cmdOut, err;
	}

	var buffer bytes.Buffer
	for _, val := range cmdOut {
		if (val == 10) {
			if(buffer.String() == path) {
				return 1,cmdOut,nil;
			}
			buffer.Reset();
			continue;
		}
		buffer.WriteString(string(val))
	}
	return 0, cmdOut, nil;
}
@

Server restart function.

<<pkg-updated.go: services>>=
func RestartService(svc string) (int, error) {
	var (
		ret int;
	)
	cmdOut,err := RunCmd("restart", svc);
	if err != nil {
		logging(LOG_ERROR, "restartservice", fmt.Sprintf("Service: Could not restart: %s | cmdOut: %v", svc, cmdOut));
		ret = 1;
	}
	return ret, err;
}
@

\newpage
\subsection{Reporting}

For general reporting, we need a logging to file function and a client program to read the informations from the database.
First we need the module for log.

<<pkg-updated.go: modules>>=
"log"
@

Need to define some constants for eventtypes.

<<pkg-updated.go: variables>>=
	const LOG_FATAL = "FATAL";
	const LOG_FATAL2 = "FATAL2";
	const LOG_DEBUG = "DEBUG";
	const LOG_INFO = "INFO";
	const LOG_ERROR = "ERROR";
	const LOG_EVENT = "EVENT";
	const LOG_STDOUT = "CONSOLE_STDOUT";
	const LOG_STDERR = "CONSOLE_STDERR";
@

The logging function does print all log message to the standard out if debug mode is enabled.
If the debug mode is not enabled, only events and fatal2 message types are printed to the standard out.
The config.FileExistsNoLog is for avoid endles log loop if reportdb not exists and the create db function will log this error.


<<pkg-updated.go: logging>>=
func logging(logtype string, facility string, msg string){
	recordtime := time.Now();
	die := 0;

	// Normal: events,
	// Debug: ALL

	if (*config.Param_DebugMode == true) {
		fmt.Printf("[%s][%s] at %s: %s\n",logtype, facility, recordtime, msg);
	} else {
		if (logtype == LOG_EVENT){
			fmt.Printf("%s\n", msg);
		}
	}

	if (logtype == "FATAL"){
		die = 1;
	}
	if (logtype == "FATAL2"){
		fmt.Printf("%s\n", msg);
		os.Exit(2);
	}
	
	config.FileExistsNoLog = true;
	ret := FileExists(config.ReportDatabaseFile);	
	if ret == 0 {
		ret := AddLogToDB(recordtime, logtype, facility, msg);	
		if ret != 0 {
			if (*config.Param_DebugMode == true) {
				fmt.Printf("[ERROR][logging] at %s: Report DB not working\n", recordtime);
			} else {
				fmt.Printf("Report DB not working\n");			
			}
		}
	}
	
	/* Need to die if fatal error happend */
	if (die >= 1){
		os.Exit(die);
	}
}
@

The [[AddLogDB]] function write all log messages into the database.
With the [[pkg-updated-report]] messages from the database can be exported as report.

<<pkg-updated.go: sqlite-connect>>=
func AddLogToDB(recordtime time.Time, logtype string, facility string, msg string) int {
	reportdb := OpenDB(config.ReportDatabaseFile);
	defer reportdb.Close();
	
	tx, err := reportdb.Begin();
	if err != nil {
		logging(LOG_FATAL2, "addtologdb", fmt.Sprintf("Error to open reportdb: %s", err));
		return -1
	}
	stmt, err := tx.Prepare("insert into report(timestamp, eventtype, facility, message) values(?, ?, ?, ?)");
	if err != nil {
		logging(LOG_FATAL2, "addtologdb", fmt.Sprintf("Can not insert into reportdb: %s", err));
		return -1;
	}
	defer stmt.Close()
	_, err = stmt.Exec(recordtime.Unix(), logtype, facility, msg);

	if err != nil {
		logging(LOG_FATAL2, "addtologdb", fmt.Sprintf("Can not insert into reportdb: %s", err));
		return -1;
	}
	tx.Commit();
	return 0;
}
@



Now comes the report client program.
This program just reads the entries from the report db and sort it by day, week or month.

The idea to create a report like with three importent informats.
1) How much packages were upgraded in the last day/week/month
2) Does rollbacks or other unexpected events occurs 
3) Are the system is uptodate or action are needed ?

<<pkg-updated-report.go: main>>=
func main(){
	// report-db-client MAIN
}
@

\newpage
\section{Check before run the program}

Before the the program will start, some pre-checks are required to be sure that no suprising errors occurs.

We need to check if the program was started as user id 0 or not.
Also check if sudo usage is configured and sudo binary are available.

For get the user id, we use the os/user module.
<<pkg-updated.go: modules>>=
"os/user"
@

First we detect the current uid and verify that sudo binary exists if enabled to use in config.

<<pkg-updated.go: check>>=
func Check() {
	var ret int;

	account,err := user.Current(); 
	if (err != nil) {
		logging(LOG_FATAL, "check", fmt.Sprintf("Could not detect user id: %s", err));
	}

	if (account.Uid != "0") {
		if (config.UseSudo == false){
			logging(LOG_EVENT, "check", "Warning: Program started as user without sudo usage, maybe it will not work !!!");
		}
	}

	if (config.UseSudo == true){
		ret = FileExists("/usr/local/bin/sudo");
		if (ret != 0){
			logging(LOG_FATAL, "check", "Error: No sudo binary (/usr/local/bin/sudo ) found, please install sudo");
		}
	}
}
@

\newpage
\subsection{Parameters}

Define the parameters for [[pkg-updated]].

<<pkg-updated-manpage>>=
-d | --debug	debug all messages
:
:

@

<<pkg-updated.go: modules>>=
"flag"
@

<<pkg-updated.go: parameter>>=
config.Param_DebugMode = flag.Bool("debug", false, "Run in debug mode");
flag.Parse();
@


\newpage
\subsection{Helper functions}

For running shell commands and reduce code, need a function to do all the necessary steps

<<pkg-updated.go: runcmd>>=
func RunCmd(cmd string, opts... string) (string, error) {
	var (
		cmdName string;
		cmdArgs []string;
		cmdOut []byte;
		err error;
		cmdArg1 []string;
	)
	cmdName = "pkg";

	switch cmd {
		case "install":
			cmdArg1 = []string{"install", "-y", "-f"};
		case "update":
			cmdArg1 = []string{"update", "-y", "-f"};
		case "lock":
			cmdArg1 = []string{"lock", "-y"};
		case "unlock":
			cmdArg1 = []string{"unlock", "-y"};
		case "upgrade":
			cmdArg1 = []string{"upgrade", "-y"};
		case "create":
			cmdArg1 = []string{"create", "-o"};			
		case "version":
			cmdArg1 = []string{"version", "-Rov"}
		case "which":
			cmdArg1 = []string{"which", "-qo"}
		case "sleep":
			_, err = exec.Command("sleep", opts[0]).CombinedOutput(); 
			return "wakeup", err; 
		case "service":
			cmdName = "service";
			cmdArg1 = []string{"-e"};
	}
	
	if (config.UseSudo == true) {
		cmdArgs = make([]string, len(cmdArg1)+1);
		cmdArgs[0] = cmdName;
		cmdName = "sudo";
		copy(cmdArgs[1:], cmdArg1);
	} else {
		cmdArgs = make([]string, len(cmdArg1));
		copy(cmdArgs, cmdArg1);
	}

	cmdArgs = append(cmdArgs, opts...);
	
	var cmdline bytes.Buffer;
	cmdline.WriteString(cmdName)
	for _,value := range cmdArgs {
		cmdline.WriteString(" ")
		cmdline.WriteString(value)
	}
	logging(LOG_DEBUG, "runcmd", fmt.Sprintf("cmd: % ", cmdline));

	cmdOut, err = exec.Command(cmdName, cmdArgs...).CombinedOutput(); 

	return string(cmdOut), err;
}
@

A small chop function for removing the new line char of a string.

<<pkg-updated.go: chop>>=
func chop(s string) string {
	return s[0:len(s)-1]
}
@


\newpage
\section{Installation of pkg-updated}

\newpage
\subsection{Install from source}

\newpage
\subsection{Install from pkg-repo}

\newpage
\subsection{Install from Ports}


\newpage
\subsection{Sudo config}

Sudo rules need

<<sudo>>=
_pkg-updated	ALL=(ALL)	NOPASSWD: /usr/sbin/pkg install -y -f *, /usr/sbin/pkg update -y -f, /usr/sbin/pkg lock -y *, /usr/sbin/pkg unlock -y *, /usr/sbin/pkg upgrade -y, /usr/sbin/pkg create -o *, /usr/sbin/pkg version -Rov, /usr/sbin/pkg which -qo *, /usr/sbin/service *
@


\newpage
\section{How to run pkg-updated}

Describe the usage and build a manpage out of it

<<manpage>>=

@

\newpage
\section{The basic pkg-updated program structure}

The pkg-update daemon program is written in golang.
The skeleton of the the program is described here.

<<pkg-updated.go>>=
<<license>>

package main

import (
	<<pkg-updated.go: modules>>
);

<<version>>
<<pkg-updated.go: variables>>
<<pkg-updated.go: check>>
<<pkg-updated.go: readconfig>>
<<pkg-updated.go: sqlite-connect>>
<<pkg-updated.go: logging>>
<<pkg-updated.go: runcmd>>
<<pkg-updated.go: chop>>
<<pkg-updated.go: syncdb>>
<<pkg-updated.go: check-updates>>
<<pkg-updated.go: lock>>
<<pkg-updated.go: rollback>>
<<pkg-updated.go: services>>
<<pkg-updated.go: update>>
<<pkg-updated.go: scheduler>>

<<pkg-updated.go: main>>
@

The structure of the pkg-update-report program.

<<pkg-updated-report.go>>=
<<license>>

package main

import (
	<<pkg-updated-report.go: modules>>
);

<<version>>
<<pkg-updated.go: variables>>
<<pkg-updated.go: readconfig>>
<<pkg-updated.go: sqlite-connect>>
<<pkg-updated.go: sqlite-connect>>

<<pkg-updated-report.go: main>>
@



\newpage
\section{License}

<<license>>=
/* 
Copyright (c) SCD-SYSTEMS.NET

The Regents of the University of California. 
All rights reserved.

Redistribution and use in source and binary forms, with 
or without modification, are permitted provided that the 
following conditions are met:

1. Redistribution's of source code must retain the above 
copyright notice, this list of conditions and 
the following disclaimer.

2. Redistribution's in binary form must reproduce the above 
copyright notice, this list of conditions and the following 
disclaimer in the documentation and/or other materials 
provided with the distribution.

3. All advertising materials mentioning features or use 
of this software must display the following 
acknowledgement: "This product includes software developed 
by the University of California, Berkeley and 
its contributors."

4. Neither the name of the University nor the names 
of its contributors may be used to endorse or promote 
products derived from this software without specific prior 
written permission.

THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS 
"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, 
BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF 
MERCHANT-ABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE 
DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS 
BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, 
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, 
BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE 
GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; 
OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON 
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT 
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) 
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, 
EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
*/
@
